# 콘서트 예약 서비스 장애 대응 매뉴얼

**작성일**: 2025년 12월 10일  
**작성자**: 문예진  

---

## 1. 개요

### 1.1 목적
본 매뉴얼은 콘서트 예약 서비스 장애 발생 시 신속한 대응을 위한 가이드입니다.

### 1.2 시스템 아키텍처

```
[Client] → [nginx LB] → [Spring Boot App (N대)]
                              ↓
                    ┌─────────┼─────────┐
                    ↓         ↓         ↓
                [MySQL]   [Redis]   [Kafka]
```

| 컴포넌트 | 역할 | 포트 |
|---------|------|------|
| Spring Boot | 애플리케이션 서버 | 8080 |
| MySQL | 메인 데이터베이스 | 3306 (호스트: 3307) |
| Redis | 캐시, 분산 락, 대기열 | 6379 |
| Kafka | 비동기 이벤트 처리 (3-broker) | 9092, 9093, 9094 |
| nginx | 로드밸런서 | 80 |

### 1.3 시스템 처리 용량 (부하 테스트 기준)

| 기능 | 최대 TPS | P95 응답시간 | P99 응답시간 | 안전 동시 사용자 |
|------|---------|-------------|-------------|-----------------|
| 잔액 조회 | 3,335/s | 66ms | 89ms | 100명 |
| 예약 플로우 | 33.4/s | 15ms | 28ms | 50명 |
| 전체 시스템 | ~2,800/s | - | - | 200명 |

**스케일 기준 (부하 테스트 검증):**

| 구간 | 동시 사용자 | 상태 | 조치 |
|------|-----------|------|------|
| 🟢 안전 | ~100명 | TPS 2,256/s, 에러 0% | 단일 인스턴스 유지 |
| 🟡 주의 | ~200명 | TPS 2,771/s (최대), CPU 포화 | 모니터링 강화 |
| 🔴 위험 | 500명+ | TPS 하락, 에러 발생 | 즉시 스케일 아웃 |

**검증된 안정성:**
- 30분 장기 부하: 메모리 누수 없음, 에러율 0%
- 50배 스파이크: 에러율 0%, 자동 복구
- 분산 환경 (2인스턴스): 중복 예약 0건

---

## 2. 장애를 대하는 자세

### 2.1 장애 발생 시 행동 원칙

> "LINE에서는 장애가 발생하면 담당자 뒤에 사람들이 우르르 몰려가서 병풍처럼 서는 모습을 '병풍친다'고 불렀습니다.
> 하지만, 프로세스가 정립되면서 굳이 담당자 뒤에 몰려가서 압박을 주지 않아도 되게 되었습니다."  
> — LINE 기술블로그

**장애 발생 시 기억할 것:**
- **당황하지 말 것** - 구글, 아마존도 장애가 발생한다. 장애는 막는 게 아니라 대응하는 것이다.
- **혼자 해결하려 하지 말 것** - 다른 팀의 시니어 개발자로부터 좋은 아이디어를 얻기도 하고, 아예 직접적인 도움을 받기도 한다
- **빠르게 공유할 것** - 장애를 숨기지 않고 적극적으로 드러내어 공유하고 장애 회고를 서로 도와야 한다.
- **원인보다 복구 우선** - 서비스 정상화가 먼저, 원인 분석은 나중이다.

> "장애는 서비스의 다양한 과정 중에서 발생하는 성장통 중 하나이다.
> 장애가 발생하는 것을 원천 차단할 방법은 없지만, 장애 대응 과정으로 서비스의 신뢰는 지킬 수 있다."  
> — 우아한형제들 기술블로그

### 2.2 회고의 중요성 (Blameless Postmortem)

> " A blamelessly written postmortem assumes that everyone involved in an incident had good intentions and did the right thing with the information they had.
> If a culture of finger pointing and shaming individuals or teams for doing the "wrong" thing prevails, people will not bring issues to light for fear of punishment."  
> — Google SRE Book

**장애 회고 원칙:**
- **누가 문제를 만들었는지 언급 금지** - 누가 장애를 냈는지가 아니라 장애 해결에 초점을 맞춰야 한다
- **시스템적 원인에 집중** - When postmortems shift from allocating blame to investigating the systematic reasons why an individual or team had incomplete or incorrect information, effective prevention plans can be put in place.
- **"Why" 대신 "What/How" 질문** - Asking “what” questions grounds the analysis in the big-picture contributing factors to the incident. Avoid asking “why” questions because it forces people to justify their actions, attributing blame.
- **매뉴얼 업데이트** - 같은 장애 발생시 다음엔 매뉴얼대로 처리

**회고에서 다룰 세 가지 관점:**
1. **장애 예방** (Preventing future outages)
2. **장애 탐지 개선** (improving outage detection) 
3. **장애 처리 개선** (improving outage handling)

> "장애를 두려워만 할 게 아니라 장애를 해결해 가는 과정을 널리 알려 플랫폼의 신뢰성을 개선하기 위한 귀중한 경험으로 삼아 함께 발전하자"  
> — LINE 기술블로그

---

## 3. 모니터링 지표 및 임계값

### 3.1 시스템 지표

| 지표 | 정상 | 주의 | 위험 | 근거 |
|------|------|------|------|------|
| CPU 사용률 | < 70% | 70~90% | > 90% | 부하 테스트 시 100%에서 TPS 하락 |
| 메모리 사용률 | < 80% | 80~90% | > 90% | 장기 부하 테스트 89%까지 안정 |
| 응답시간 (P95) | < 100ms | 100~500ms | > 500ms | 부하 테스트 P95 66ms, SLO 500ms |
| 에러율 | < 0.1% | 0.1~1% | > 1% | 부하 테스트 0%, SLO 1% |
| DB 커넥션 | < 8개 | 8~9개 | 10개 | `maximum-pool-size: 10` (application.yml) |
| Redis 메모리 | < 70% | 70~85% | > 85% | Redis 공식 권장 |

### 3.2 비즈니스 지표

| 지표 | 정상 | 이상 징후 | 근거 |
|------|------|----------|------|
| 대기열 처리 | 5분 이내 | 10분 이상 적체 | 토큰 TTL 10분 (`QueueService.java`) |
| 좌석 점유 | 5분 이내 결제 | 5분 초과 미결제 | `Duration.ofMinutes(5)` (`ReservationService.java`) |
| 결제 처리 | 5분 이내 완료 | 5분 초과 타임아웃 | `PAYMENT_TIMEOUT_MINUTES = 5` (`PaymentTimeoutScheduler.java`) |
| 토큰 발급 | 정상 응답 | 연속 3회 실패 | 분산락 재시도 3회 (`ReservationService.java`) |
| 결제 처리량 | 피크 타임 정상 | 피크 타임 0건 | 우아한형제들 참고 |

### 3.3 스케줄러 정상 동작 확인

| 스케줄러 | 실행 주기 | 로그 키워드 | 코드 출처 |
|---------|------|----------|----------|
| 좌석 점유 정리 | 10초 | `[좌석점유정리]` | `CleanupScheduler.java` |
| 큐 토큰 정리 | 30초 | `[큐토큰정리]` | `CleanupScheduler.java` |
| 임시 예약 정리 | 1분 | `[예약정리]` | `CleanupScheduler.java` |
| 결제 타임아웃 | 1분 | `결제 타임아웃 처리` | `PaymentTimeoutScheduler.java` |
| 스케줄러 상태 | 5분 | `[스케줄러상태]` | `CleanupScheduler.java` |
| 오래된 데이터 | 매일 03:00 | `[일일정리]` | `CleanupScheduler.java` |

---

## 4. 장애 대응 프로세스

```
┌────────────────────────────────────┐
│  인지 → 전파 → 분석 → 해결 → 보고 → 회고  │
│   ↑                             │  │
│   └─────────────────────────────┘  │
│            (매뉴얼 업데이트)           │
└────────────────────────────────────┘
```

### 4.1 인지 (Detection)
- 모니터링 알람 (Slack)
- CS팀 문의 접수
- 내부 테스트 중 발견
- 외부 연동 시스템 알람

### 4.2 전파 (Communication)

**전파 대상 및 순서:**
1. **개발팀** - Slack #incident 채널
2. **CS팀** - 고객 응대 준비
3. **관련 팀** - API 사용 팀

### 4.3 분석 (Analysis)
- **원인 파악보다 서비스 정상화 우선**
- 배포 직후 장애 → 롤백 먼저 고려
- 매뉴얼에 있는 장애 → 매뉴얼대로 처리

### 4.4 해결 (Resolution)
- 즉시 조치 실행
- **1시간 간격으로 상황 업데이트 전파**
- 복구 완료 시 전파

### 4.5 보고 (Report)
- 장애 종료 후 **1일 이내** 1차 보고
- 장애 보고서 작성 (8장 템플릿 참고)

### 4.6 회고 (Retrospective)
- 장애 발생 후 **5일 이내** 회고 진행
- 장애 회고 템플릿 사용 (9장 템플릿 참고)
- 액션 아이템 Jira 티켓 등록

---

## 5. 장애 대응 시나리오

### 5.1 시나리오: 티켓 오픈 시간 트래픽 급증

**상황:** 인기 콘서트 티켓 오픈 시간에 동시 접속자 500명 이상 발생

**Step 1: 알람 발생**
```
📍 알람 발생 위치: Slack #monitoring-alert
📍 알람 내용: "CPU 사용률 95% 초과, 응답시간 500ms 초과"
📍 알람 수신자: 온콜 담당자 (당번제 운영)
```

**Step 2: 초기 대응 (5분 이내)**
```
📍 온콜 담당자 행동:
   1. Slack #incident 채널에 장애 선언
   2. 현재 상태 확인 (docker stats, 로그)
   3. 팀 리더에게 보고

📍 Slack #incident 메시지:
   🚨 [장애 발생 - P2]
   - 시간: 2025-12-09 20:00
   - 증상: 응답시간 급증, 일부 타임아웃
   - 영향: 예약 플로우 지연
   - 담당: 문예진
   - 조치 중: 스케일 아웃 진행
```

**Step 3: 고객 공지**
```
📍 공지 내용:
   "현재 접속자가 많아 일시적으로 지연이 발생하고 있습니다.
    대기열 순서대로 입장되오니 잠시만 기다려 주세요.
    이용에 불편을 드려 죄송합니다."
```

**Step 4: 조치**
```bash
# 1. 현재 상태 확인
docker stats
docker compose logs app --tail 200 | grep -E "(ERROR|WARN|timeout)"

# 2. 대기열 상태 확인 (Redis)
docker exec concert-redis redis-cli ZCARD queue:waiting
docker exec concert-redis redis-cli SCARD queue:active
docker exec concert-redis redis-cli GET queue:active:counter

# 3. 스케일 아웃 (컨테이너 추가)
docker compose up -d --scale app=3
```

**Step 5: 모니터링 및 안정화 확인**
```bash
# 응답시간 정상화 확인
curl -w "@curl-format.txt" -o /dev/null -s http://localhost:8080/api/concerts

# 간단하게 응답시간만 확인
curl -w "응답시간: %{time_total}s\n" -o /dev/null -s http://localhost:8080/api/concerts

# 에러율 확인
docker compose logs app --since 5m | grep -c "ERROR"
```

**Step 6: 복구 완료 전파**
```
✅ [장애 복구 완료]
- 복구 시간: 2025-12-09 20:15
- 장애 시간: 15분
- 원인: 티켓 오픈 시간 트래픽 급증 (동시 접속 500명+)
- 조치: 스케일 아웃 (인스턴스 1→3)
- 영향: 일부 사용자 응답 지연 (타임아웃 약 20건)
- 후속 조치: 오픈 시간 전 사전 스케일 아웃 절차 수립
- 회고 일정: 2025-12-10 14:00
```

**Step 7: 고객 복구 공지**
```
📍 공지 내용:
   "접속 지연이 해소되었습니다.
    지연 시간: 20:00 ~ 20:15 (약 15분)
    이용에 불편을 드려 죄송합니다."
```

**Step 8: 트래픽 정상화 후 스케일 인**
```bash
# 트래픽 안정화 확인 후 (보통 오픈 후 30분~1시간)
docker compose up -d --scale app=1

# 리소스 정리
docker system prune -f
```

---

### 5.2 시나리오: Redis 장애로 분산 락 실패

**상황:** Redis 연결 실패로 좌석 배정 불가

**Step 1: 알람 발생**
```
📍 알람: "RedisConnectionException 다수 발생"
📍 영향: 좌석 배정 API 전체 실패
📍 등급: P1 (핵심 기능 장애)
```

**Step 2: 초기 대응**
```
📍 Slack #incident 메시지:
   🚨 [장애 발생 - P1]
   - 시간: 2025-12-09 19:30
   - 증상: 좌석 배정 전체 실패
   - 영향: 예약 불가
   - 담당: 문예진
   - 원인 추정: Redis 연결 장애
```

**Step 3: 고객 공지**
```
📍 공지 내용:
   "현재 좌석 예약 기능에 일시적인 장애가 발생했습니다.
    복구 작업 중이며, 정상화 후 다시 안내드리겠습니다.
    불편을 드려 대단히 죄송합니다."
```

**Step 4: 조치**
```bash
# 1. Redis 상태 확인
docker exec concert-redis redis-cli ping
docker compose logs app --tail 100 | grep -i redis

# 2. Redis 재시작
docker restart concert-redis

# 3. 연결 확인
docker exec concert-redis redis-cli info clients

# 4. 애플리케이션 정상 동작 확인
curl http://localhost:8080/actuator/health
curl http://localhost:8080/api/concerts
curl http://localhost:8080/api/queue/status
```

**Step 5: 복구 후 데이터 정합성 확인**
```sql
-- 장애 시간대 예약 확인
SELECT * FROM seat_hold
WHERE created_at BETWEEN '2025-12-09 19:30:00' AND '2025-12-09 19:45:00';

-- 중복 예약 확인
SELECT seat_id, COUNT(*) as cnt
FROM seat_hold
WHERE status = 'CONFIRMED'
GROUP BY seat_id
HAVING cnt > 1;

-- 미완료 결제 확인
SELECT * FROM reservation
WHERE status = 'PAYMENT_PENDING'
  AND created_at BETWEEN '2025-12-09 19:30:00' AND '2025-12-09 19:45:00';
```

**Step 6: 복구 완료 전파**
```
✅ [장애 복구 완료]
- 복구 시간: 2025-12-09 19:45
- 장애 시간: 15분
- 원인: Redis 메모리 부족으로 연결 거부
- 조치: Redis 재시작 및 메모리 정리
- 영향: 장애 시간 동안 좌석 배정 약 50건 실패
- 후속 조치: Redis 메모리 모니터링 알람 추가 예정
- 회고 일정: 2025-12-10 14:00
```

**Step 7: 고객 복구 공지**
```
📍 공지 내용:
   "좌석 예약 기능이 정상화되었습니다.
    장애 시간: 19:30 ~ 19:45 (약 15분)
    이용에 불편을 드려 죄송합니다."
```

---

### 5.3 시나리오: 원인 불명 장애

**상황:** 알 수 없는 이유로 서비스 불안정

**Step 1: 알람 발생 및 장애 선언**
```
📍 Slack #incident 메시지:
   🚨 [장애 발생 - P2]
   - 시간: 2025-12-09 21:00
   - 증상: 서비스 불안정 (원인 파악 중)
   - 영향: 일부 기능 간헐적 오류
   - 담당: 문예진
   - 상태: 원인 분석 중
```

**Step 2: 고객 공지**
```
📍 공지 내용:
   "현재 일시적인 서비스 장애가 발생했습니다.
    원인 파악 및 복구 작업 중이며, 정상화 후 안내드리겠습니다.
    불편을 드려 죄송합니다."
```

**Step 3: 당황하지 말고 기본부터**
```bash
# 1. 모든 컨테이너 상태 확인
docker ps -a --format "table {{.Names}}\t{{.Status}}"

# 2. 리소스 확인
docker stats --no-stream

# 3. 최근 로그 수집
docker compose logs app --since 30m > app-log.txt
docker logs concert-mysql --since 30m > mysql-log.txt
docker logs concert-redis --since 30m > redis-log.txt
docker logs concert-kafka-1 --since 30m > kafka-log.txt

# 4. 에러 패턴 확인
grep -E "(ERROR|Exception|timeout)" app-log.txt | head -50
```

**Step 4: 최근 변경사항 확인**
```
📍 체크리스트:
   □ 최근 배포가 있었나? → YES면 Step 5로
   □ 트래픽 급증이 있었나? → 5.1 시나리오 참고
   □ 외부 API 장애인가? → 외부 서비스 상태 페이지 확인
   □ 인프라 변경이 있었나? → 클라우드 콘솔 확인
   □ 인증서/크레덴셜 만료? → 만료일 확인
```

**Step 5: 롤백 (배포 직후라면)**
```bash
# 이전 버전으로 롤백
docker pull app:previous-version
docker compose up -d

# 롤백 후 정상화 확인
curl http://localhost:8080/actuator/health
```

**Step 6: 도움 요청 (10분 내 원인 파악 실패 시)**
```
📍 Slack #incident 메시지:
   🆘 [도움 요청]
   - 상황: 원인 파악 어려움 (10분 경과)
   - 증상: (구체적으로)
   - 시도한 것: (나열)
   - 로그 파일: (첨부)
   - 필요한 것: 추가 분석 인력

📍 중요: 혼자 해결하려고 시간 끌지 말 것!
```

**Step 7: 복구 완료 전파**
```
✅ [장애 복구 완료]
- 복구 시간: 2025-12-09 21:30
- 장애 시간: 30분
- 원인: (파악된 원인 기재)
- 조치: (수행한 조치 기재)
- 영향: (영향 범위 기재)
- 후속 조치: 원인 분석 및 재발 방지책 수립
- 회고 일정: 2025-12-10 14:00
```

**Step 8: 고객 복구 공지**
```
📍 공지 내용:
   "서비스가 정상화되었습니다.
    장애 시간: 21:00 ~ 21:30 (약 30분)
    이용에 불편을 드려 죄송합니다."
```

---

## 6. 예측 가능한 장애 대응 (Runbook)

> **완벽히 개선이 어려운 포인트**에 대한 대응 매뉴얼

### 6.1 OOM (메모리 부족)

| 항목 | 내용 |
|------|------|
| **분류** | 개선 어려움 (JVM 특성상 일정 메모리 필요) |
| **증상** | 컨테이너 재시작, `OutOfMemoryError` 로그 |
| **근본 해결** | 메모리 512MB 이상 유지 (256MB 서비스 불가 - 부하 테스트 검증) |

**확인 및 조치:**
```bash
# 확인
docker compose logs app --tail 100 | grep -i "outofmemory"

# 즉시 조치
docker compose restart app
```

---

### 6.2 트래픽 급증 (TPS 포화)

| 항목 | 내용 |
|------|------|
| **분류** | 개선 어려움 (티켓팅 특성상 불가피) |
| **증상** | 응답시간 급증, CPU 100%, 간헐적 타임아웃 |
| **임계값** | 100명(모니터링) → 200명(준비) → 500명(스케일 아웃) |
| **상세 시나리오** | 5.1 참고 |

**즉시 조치:**
```bash
docker compose up -d --scale app=3
```

---

### 6.3 Redis 장애

| 항목 | 내용 |
|------|------|
| **분류** | 예측 가능 |
| **증상** | 토큰 발급 실패, 분산 락 실패, `RedisConnectionException` |
| **영향** | 좌석 배정 불가, 대기열 불가, 캐시 미스 → DB 부하 증가 |
| **상세 시나리오** | 5.2 참고 |

**확인 및 조치:**
```bash
# 확인
docker exec concert-redis redis-cli ping

# 즉시 조치
docker restart concert-redis
```

---

### 6.4 MySQL 커넥션 풀 고갈

| 항목 | 내용 |
|------|------|
| **분류** | 예측 가능 |
| **증상** | 전체 API 지연, `Connection is not available` 로그 |
| **임계값** | 8개(주의) / 9개(위험) / 10개(최대) |

**확인 및 조치:**
```bash
# 1. 컨테이너 확인
docker ps -a | grep mysql

# 2-1. 꺼져있으면
docker start concert-mysql

# 2-2. 실행 중이면 (비밀번호는 환경에 맞게 입력)
docker exec -it concert-mysql mysql -uroot -p -e "SHOW PROCESSLIST;"

# 3. 즉시 조치
docker compose restart app
```

---

## 7. 예측 불가 장애 대응

> **아예 예측을 못한 포인트**에 대한 대응 매뉴얼

### 7.1 Kafka 브로커 다운

| 항목 | 내용 |
|------|------|
| **증상** | 결제 확정 후 상태 미변경, `KafkaException` 로그 |
| **영향** | 결제 상태 업데이트 지연 (**예약/좌석 배정은 정상**) |
| **후속** | 미처리 메시지 확인, DB 기반 수동 재처리 |

**확인 및 조치:**
```bash
# 확인
docker logs concert-kafka-1 --tail 50

# 즉시 조치
docker restart concert-kafka-1 concert-kafka-2 concert-kafka-3
```

---

### 7.2 외부 결제 시스템 장애

| 항목 | 내용 |
|------|------|
| **증상** | 결제 타임아웃, 상태 불일치 |
| **즉시 조치** | 결제 기능 임시 중단 + 고객 공지 |
| **후속** | 불일치 건 수동 확인, 환불/재결제 처리 |

---

### 7.3 원인 불명 장애

| 항목 | 내용 |
|------|------|
| **대응 원칙** | ① 롤백 먼저 → ② 로그 수집 → ③ 도움 요청 |
| **중요** | 혼자 해결하려 하지 말 것 (10분 내 에스컬레이션) |
| **상세 시나리오** | 5.3 참고 |

**로그 수집:**
```bash
docker compose logs app --since 30m > app-log.txt
```

---
## 8. 장애 보고서 템플릿

```markdown
# 장애 보고서

## 1. 장애 요약

| 항목 | 내용 |
|------|------|
| 장애 등급 | P1 / P2 / P3 |
| 발생 시간 | YYYY-MM-DD HH:MM |
| 복구 시간 | YYYY-MM-DD HH:MM |
| 장애 지속 | X분 |
| 영향 범위 | (영향받은 기능, 사용자 수) |

## 2. 장애 탐지

| 항목 | 내용 |
|------|------|
| 탐지 시각 | |
| 탐지 경로 | 모니터링 알람 / CS 문의 / 내부 발견 |
| 최초 인지자 | |

## 3. 영향받은 서비스
- 

## 4. 장애 원인
- 

## 5. 타임라인

| 시간 | 행동 | 결과 |
|------|------|------|
| HH:MM | 장애 인지 | |
| HH:MM | 팀 전파 | |
| HH:MM | 원인 분석 | |
| HH:MM | 조치 실행 | |
| HH:MM | 서비스 정상화 | |

## 6. 재발 방지 대책

| 관점 | 개선 항목 | 담당자 | 기한 |
|------|----------|--------|------|
| 장애 예방 | | | |
| 장애 탐지 | | | |
| 장애 대응 | | | |

## 7. 추가 조치 필요 사항
- 
```

---

## 9. 장애 회고 템플릿

```markdown
# 장애 회고

**일시:** YYYY-MM-DD HH:MM  
**참석자:** (장애 대응 팀, 관련 팀)  
**진행자:** 

---

## 1. 장애 요약 
- 장애 보고서 내용 공유

## 2. 타임라인 리뷰
- 각 단계별 행동 검토
- 더 빠르게 할 수 있었던 부분?

## 3. 논의 사항

### 3.1 장애 예방 관점
- 이 장애를 사전에 막을 수 있었나?
- 빠진 테스트가 있었나?

### 3.2 장애 탐지 관점
- 알람이 제대로 왔나?
- 더 빨리 인지할 수 있었나?

### 3.3 장애 대응 관점
- 다른 방법을 선택했다면 더 빨랐을까?
- 매뉴얼이 도움이 됐나?

## 4. 액션 아이템

## 5. 잘한 점
- 

## 6. 개선할 점
- 

---

⚠️ **회고 원칙**
- 누가 만들었는지 언급 금지
- 어떻게 개선할지에 집중
- 비난 없이 건설적으로
```

---

## 10. 에스컬레이션 절차

### 10.1 장애 등급 기준

| 등급 | 기준 | 예시 | 대응 시간 |
|------|------|------|----------|
| **P1** | 전체 서비스 중단 | 예약 불가, 결제 불가 | 즉시 |
| **P2** | 주요 기능 장애 | 특정 API 오류, 성능 저하 | 30분 이내 |
| **P3** | 부분 기능 오류 | 마이너 버그, 우회 가능 | 업무 시간 내 |

### 10.2 에스컬레이션 경로

```
[P3] 담당 개발자 → 팀 리더
[P2] 담당 개발자 → 팀 리더 → 관련 팀
[P1] 담당 개발자 → 팀 리더 → 전체 개발팀 → 경영진 → CS팀
```

### 10.3 역할별 책임

| 역할     | 책임 |
|--------|------|
| 온콜 담당자 | 알람 확인, 초기 대응, 전파 |
| 팀 리더   | 장애 대응 총괄, 의사결정, 상황 업데이트 |
| 개발자    | 원인 분석, 수정, 배포 |
| CS팀    | 고객 문의 대응, 공지 발송 |

### 10.4 연락처

| 역할     | 담당자 | 연락 방법 |
|--------|--------|----------|
| 개발팀 리더 | - | Slack / 전화 |
| 인프라 담당 | - | Slack / 전화 |
| CS팀    | - | Slack #cs-support |

---

## 11. 부록

### 참고 자료

**장애 대응 문화**
- [LINE 플랫폼 서버의 장애 대응 프로세스와 문화](https://engineering.linecorp.com/ko/blog/line-platform-server-outage-process-and-dev-culture)
- [LINE의 장애 보고와 후속 절차 문화](https://engineering.linecorp.com/ko/blog/line-failure-reporting-and-follow-up-process-culture)
- [우아~한 장애대응 | 우아한형제들 기술블로그](https://techblog.woowahan.com/4886/)
- [구름 세미나 - 장애 대응 경험 공유](https://tech.goorm.io/goormseminar_3rd/)

**Blameless Postmortem**
- [Google SRE Book - Postmortem Culture](https://sre.google/sre-book/postmortem-culture/)
- [Google SRE Workbook - Postmortem Culture](https://sre.google/workbook/postmortem-culture/)
- [PagerDuty - Blameless Culture](https://postmortems.pagerduty.com/culture/blameless/)

**SLO/SLA/SLI**
- [New Relic - SLO, SLI, SLA란?](https://newrelic.com/kr/blog/best-practices/what-are-slos-slis-slas)
- [Google Cloud - SLO 모니터링](https://cloud.google.com/stackdriver/docs/solutions/slo-monitoring?hl=ko)
- [AWS - 서비스 수준 계약이란?](https://aws.amazon.com/ko/what-is/service-level-agreement/)

### 느낀점

라인과 우아한의 읽으면서 가장 인상 깊었던 것은 "장애를 두려워하지 말고 귀중한 경험으로 바꿔라"는 LINE의 철학이었습니다.

장애라고 하면 무섭고 피하고 싶은 존재였는데, 이 글들을 통해 장애를 대하는 관점이 바뀌었습니다. 장애는 서비스가 성장하면서 겪는 성장통이고, 완벽히 막을 수는 없지만 어떻게 대응하느냐가 중요하다는 것을 배웠습니다.

특히 우아한형제들의 "비즈니스 지표를 기준으로 한 알람"이 인상적이었습니다. 시스템 지표만 보는 게 아니라, 피크 타임에 매출이 0이면 장애일 수 있다는 관점은 생각해보지 못했던 부분이었습니다.

또한 LINE에서 장애 티켓을 OKR로 관리하여 83%가 해결됐거나 해결되고 있는 상태라는 사례를 보며, 프로세스만으로는 부족하고 문화가 뒷받침되어야 한다는 점을 깨달았습니다. 아무리 좋은 매뉴얼도 조직에서 실행하지 않으면 의미가 없다는 교훈을 얻었습니다.

매뉴얼을 작성하면서 부하 테스트 데이터를 기반으로 구체적인 임계값을 정할 수 있었고, 실제 장애 상황에서 어떻게 대응해야 할지 시뮬레이션해볼 수 있었습니다. 앞으로 장애가 발생하면 당황하지 않고 매뉴얼을 따라 체계적으로 대응할 수 있을 것 같습니다.

회고 원칙을 정리하면서 "누가 만들었는지 언급 금지"라는 규칙이 처음엔 신기했습니다. 원인을 찾으려면 누가 했는지 알아야 하는 거 아닌가?라고 생각해왔기 때문입니다.

그런데 "Why"라고 물으면 사람들이 방어적이 된다고 했습니다. "왜 그렇게 했어?"보다 "그때 어떤 정보를 갖고 있었어?"라고 물어야 진짜 원인을 찾을 수 있다는 거였습니다. 누구인지 추궁하고 사람이 몰려들면 그 개발자는 두려움과 압박감이 생길 수 있다는 걸 느꼈습니다.

아직 회고를 해본 적은 없지만, 나중에 이런 상황이 오면 비난하지 않는 분위기를 만드는 게 중요하다는 걸 기억해야겠습니다.

솔직히 이 매뉴얼은 실제 장애 경험 없이 만든 것이라 부족한 부분이 많을 것 같습니다. 실제로 장애가 터지면 매뉴얼대로 안 될 수도 있고, 빠진 부분도 있을 것 같습니다.

하지만 이렇게라도 한 번 정리해보니 장애가 나면 뭘 먼저 해야 하는지 순서가 머릿속에 그려지고, 장애가 발생하면 "일단 로그부터 보자"라고 생각하게 되었습니다. 또한, 혼자 끙끙대지 말고 도움 요청해야겠다고 다짐했습니다.

---
