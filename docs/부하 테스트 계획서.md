# 콘서트 예약 시스템 부하 테스트 계획서

**작성일**: 2025년 12월 8일  
**작성자**: 문예진  
**문서 목적**: 부하 테스트 필요성 및 실행 계획 보고

---

## 0. Executive Summary

### 왜 부하 테스트가 필요한가?

콘서트 예약 서비스는 **티켓 오픈 순간 수천~수만 명이 동시 접속**하는 특수한 트래픽 패턴을 가집니다. 이 순간 시스템이 제대로 동작하지 않으면 **매출 손실, 고객 이탈, 브랜드 이미지 훼손**으로 이어집니다.

현재 시스템은 다음 질문에 답할 수 없습니다:
- 동시 접속자 몇 명까지 처리할 수 있는가?
- 서버 스펙은 적정한가? (과투자 또는 과소투자?)
- 동시 예약 시 중복 배정이 발생하지 않는가?

**부하 테스트를 통해 이 질문들에 답하고, 안정적인 서비스 운영 기반을 마련하고자 합니다.**

---

### 테스트하지 않을 경우 리스크

| 리스크 | 발생 시나리오 | 예상 손실 |
|--------|-------------|----------|
| **서버 다운** | 티켓 오픈 시 트래픽 폭주로 서버 무응답 | 티켓 판매 불가, 매출 손실, SNS 악평 확산 |
| **중복 예약** | 동시 요청 시 같은 좌석 2명에게 배정 | 현장 혼란, 보상 비용, 법적 분쟁 가능성 |
| **중복 결제** | 동시성 제어 실패로 이중 차감 | 환불 처리 비용, 고객 신뢰도 하락 |
| **느린 응답** | 결제까지 10초 이상 소요 | 이탈률 증가, 경쟁사로 고객 유출 |

> **핵심**: 티켓 오픈은 **단 한 번의 기회**입니다. 실패하면 복구할 수 없습니다.

---

### 기대 효과

| 효과 | 설명 |
|------|------|
| **장애 예방** | 사전에 병목 구간 발견 및 개선 |
| **비용 최적화** | 적정 서버 스펙 도출로 인프라 비용 절감 |
| **신뢰성 확보** | 동시성 제어 검증으로 중복 예약 0건 보장 |
| **의사결정 근거** | 스케일 아웃 시점, 캐시 도입 등 데이터 기반 판단 |

---

## 1. 개요

### 1.1 배경

콘서트 예약 서비스는 티켓 오픈 시 순간적으로 트래픽이 집중되는 특성이 있습니다. 특히 결제 처리는 사용자 잔액의 정확성이 보장되어야 하며, 동시 요청 상황에서도 데이터 정합성이 유지되어야 합니다.

이는 금융 시스템의 계좌이체와 동일한 수준의 신뢰성을 요구합니다:
- 중복 결제 방지
- 잔액 정합성 100% 보장
- 동시 요청 시 순서 보장

### 1.2 목적

| 목적 | 설명 |
|------|------|
| **한계점 파악** | 시스템의 최대 처리량(TPS) 및 장애 발생 시점 확인 |
| **적정 스펙 도출** | CPU/Memory별 성능 비교로 비용 최적화 |
| **병목 식별** | DB, Redis, 네트워크 등 개선 우선순위 수립 |
| **SLA 기준 수립** | 응답시간, 에러율 등 서비스 수준 목표 설정 |
| **동시성 검증** | 좌석 중복 예약 방지 확인 |

---

## 2. 테스트 대상 선정

### 2.1 어떤 API를 테스트하는가?

| 우선순위 | API | 선정 이유 |
|---------|-----|----------|
| 1 | `GET /api/wallet/{userId}/balance` | 가장 빈번한 호출, 리소스별 성능 비교 기준점 |
| 2 | `POST /api/queue/token` + `POST /api/reservations/temporary-assign` | 티켓팅 핵심 플로우, 동시성 제어 검증 |
| 3 | `POST /api/reservations/confirm` | 결제 처리, 잔액 정합성 검증 |

### 2.2 왜 이 API들인가?

**잔액 조회 API (1순위)**
- **빈도**: 사용자가 가장 자주 호출하는 API
- **목적**: 단순 읽기 작업으로 서버 스펙별 순수 성능 비교 가능
- **리스크**: 느린 응답 시 사용자 이탈

**예약 플로우 (2순위)**
- **빈도**: 티켓 오픈 순간 집중 호출
- **목적**: Redis 분산 락 기반 동시성 제어 검증
- **리스크**: 실패 시 중복 좌석 배정 → 현장 혼란, 보상 비용

**결제 확정 API (3순위)**
- **빈도**: 예약 성공 사용자만 호출
- **목적**: Kafka 비동기 처리 + 잔액 차감 정합성 검증
- **리스크**: 실패 시 중복 결제 → 환불 처리, 고객 신뢰 하락

---

## 3. 테스트 시나리오

### 테스트 유형 개요

| 유형 | 목적 | 질문에 대한 답 |
|------|------|---------------|
| **리소스별 성능 비교** | 적정 배포 스펙 도출 | "서버 스펙을 얼마로 해야 하는가?" |
| **동시성 경쟁 테스트** | 동시성 제어 검증 | "500명이 동시에 예약해도 중복이 없는가?" |
| **스케일 테스트** | 대규모 유저 풀 검증 | "유저가 10,000명이어도 동일하게 동작하는가?" |
| **E2E 플로우 테스트** | 전체 흐름 검증 | "예약부터 결제까지 정상 동작하는가?" |
| **스트레스 테스트** | 시스템 한계점 파악 | "어느 시점에 시스템이 죽는가?" |
| **스파이크 테스트** | 순간 급증 대응 | "티켓 오픈 순간 50배 트래픽을 버티는가?" |
| **장기 부하 테스트** | 안정성 검증 | "30분 이상 운영해도 메모리 누수가 없는가?" |

---

### 3.1 잔액 조회 테스트 (리소스별 비교)

**목적**: 서버 스펙별 성능 차이를 측정하여 **비용 대비 최적 스펙** 도출

| 단계 | Docker 스펙 | 동시 사용자 | 지속 시간 | 측정 지표 |
|------|------------|-----------|----------|----------|
| 1단계 | 0.25 CPU, 256MB | 100 | 60초 | TPS, 응답시간, 에러율 |
| 2단계 | 0.5 CPU, 512MB | 100 | 60초 | TPS, 응답시간, 에러율 |
| 3단계 | 1 CPU, 512MB | 100 | 60초 | TPS, 응답시간, 에러율 |
| 4단계 | 2 CPU, 1GB | 100 | 60초 | TPS, 응답시간, 에러율 |

**이 테스트로 알 수 있는 것**:
- CPU 2배 증가 시 TPS가 얼마나 향상되는가?
- 메모리 부족 시 어떤 증상이 나타나는가?
- 비용 대비 가장 효율적인 스펙은?

---

### 3.2 예약 플로우 테스트 (동시성 경쟁)

**목적**: 다수 사용자가 **동시에 같은 좌석을 예약**할 때 **중복 없이 정확히 처리**되는지 검증

| 시나리오 | 동시 사용자 | 대상 좌석 | 예상 결과 |
|---------|-----------|----------|----------|
| 기본 경쟁 | 50명 | 50석 | 50건 예약, 중복 0건 |
| 2배 경쟁 | 100명 | 50석 | 50건 예약, 중복 0건 |
| 10배 경쟁 | 500명 | 50석 | 50건 예약, 중복 0건 |

**테스트 플로우**:
```
1. 대기열 토큰 발급 → POST /api/queue/token?userId={uuid}
2. 좌석 임시 배정   → POST /api/reservations/temporary-assign (X-Queue-Token 헤더)
```

**핵심 검증 항목**:
- 예약 성공 건수 = 좌석 수 (50건)
- 중복 예약 = 0건 (절대 발생 불가)
- 좌석별 단일 예약만 존재

---

### 3.3 스케일 테스트 (대규모 유저 풀)

**목적**: 실제 서비스와 유사한 **10,000명 유저 풀**에서 동일한 성능이 나오는지 검증

| 시나리오 | 유저 풀 | 동시 사용자 | 대상 좌석 | 목적 |
|---------|--------|-----------|----------|------|
| 기본 | 500명 | 500명 | 50석 | 기준 성능 측정 |
| 대규모 | 10,000명 | 500명 | 50석 | 대규모 유저 풀에서 동일 성능 확인 |
| 극한 | 10,000명 | 1,000명+ | 50석 | 시스템 한계점 파악 |

> **참고**: JMeter 로컬 실행 시 약 4,000~5,000 스레드가 한계입니다.
> 10,000명 동시 테스트는 분산 JMeter 또는 클라우드 부하 테스트 도구가 필요합니다.

---

### 3.4 E2E 플로우 테스트 (결제 확정)

**목적**: 토큰 발급 → 좌석 배정 → **결제 확정**까지 전체 흐름이 정상 동작하는지 검증

| 시나리오 | 동시 사용자 | 지속 시간 | 측정 지표 |
|---------|-----------|----------|----------|
| 단일 사용자 | 1명 | - | 전체 플로우 정상 동작 확인 |
| 소규모 동시 | 10명 | 60초 | 결제 성공률, 잔액 정합성 |
| 중규모 동시 | 50명 | 60초 | TPS, 응답시간, 결제 성공률 |

**테스트 플로우**:
```
1. 대기열 토큰 발급 → POST /api/queue/token?userId={uuid}
2. 좌석 임시 배정   → POST /api/reservations/temporary-assign
3. 결제 확정       → POST /api/reservations/confirm (Idempotency-Key 헤더)
4. 잔액 검증       → GET /api/wallet/{userId}/balance
```

**핵심 검증 항목**:
- 결제 완료 후 잔액 = 초기 잔액 - 티켓 가격
- 예약 상태 = CONFIRMED
- 중복 결제 방지 (Idempotency-Key로 동일 요청 재시도 시 1회만 처리)

---

### 3.5 스트레스 테스트 (한계점 파악)

**목적**: 시스템이 **어느 시점에 장애가 발생**하는지 파악하여 스케일 아웃 기준 수립

| 단계 | 동시 사용자 | 목표 TPS | 지속 시간 | 관찰 지표 |
|------|-----------|---------|----------|----------|
| 1단계 | 100 | ~500 | 2분 | 정상 동작 기준선 |
| 2단계 | 200 | ~1,000 | 2분 | 응답시간 증가 시점 |
| 3단계 | 500 | ~2,000 | 2분 | 에러 발생 시점 |
| 4단계 | 1,000+ | 한계까지 | 2분 | 시스템 장애 시점 |

**측정 지표**:
- TPS 포화 시점 (더 이상 증가하지 않는 지점)
- 응답시간 급증 시점 (P95 > 1초)
- 에러율 1% 초과 시점
- OOM 또는 커넥션 풀 고갈 시점

**이 테스트로 알 수 있는 것**:
- "동시 접속 N명까지는 안전하다"
- "N명 초과 시 서버 증설이 필요하다"

---

### 3.6 스파이크 테스트 (티켓 오픈 시뮬레이션)

**목적**: 티켓 오픈 순간 **5초 내 50배 트래픽 급증** 시 시스템 안정성 검증

| 구간 | 시간 | 동시 사용자 | 시나리오 |
|------|------|-----------|---------|
| 대기 | 0~30초 | 10명 | 평상시 트래픽 |
| 급증 | 30~35초 | 10 → 500명 | 티켓 오픈 순간 (5초 내 50배 급증) |
| 유지 | 35~90초 | 500명 | 피크 트래픽 유지 |
| 감소 | 90~120초 | 500 → 50명 | 트래픽 안정화 |

**핵심 검증 항목**:
- 급증 구간에서 시스템 다운 여부
- 에러율 급증 여부 (허용: 5% 이내)
- 트래픽 감소 후 자동 복구 여부

---

### 3.7 장기 부하 테스트

**목적**: 30분 이상 지속 운영 시 **메모리 누수, 성능 저하** 여부 검증

| 항목 | 설정값 |
|------|--------|
| 동시 사용자 | 100명 |
| 지속 시간 | 30분 ~ 1시간 |
| 요청 패턴 | 일정 부하 유지 |

**핵심 검증 항목**:
- 메모리 사용량 추이 (계속 증가하면 누수)
- 응답시간 변화 추이 (점점 느려지면 문제)
- DB 커넥션 풀 상태
- 에러율 변화

---

## 4. 성공 기준

| 지표 | 기준 | 비고 |
|------|------|------|
| 응답 시간 P95 | < 500ms | 사용자 체감 품질 |
| 응답 시간 P99 | < 1000ms | 최악 상황 허용치 |
| 에러율 (시스템) | < 1% | 비즈니스 에러 제외 |
| TPS (잔액조회) | > 500 | 최소 목표 |
| TPS (예약플로우) | > 50 | 동시성 제어 포함 |
| **중복 예약** | **0건** | 동시성 제어 핵심 지표 |
| **데이터 정합성** | **100%** | 좌석별 단일 예약 보장 |

---

## 5. 테스트 환경

### 5.1 인프라 구성

| 구성요소 | 스펙 | 비고 |
|---------|------|------|
| Application | Docker (스펙 가변) | Spring Boot 3.x |
| Database | MySQL 8.0 (Docker) | 기본 설정 |
| Cache/Lock | Redis 7.x (Docker) | 대기열, 분산 락 |
| Message Queue | Kafka 7.5.0 (Docker) | 3-broker 클러스터 |
| Load Generator | JMeter 5.6.3 | CLI 모드 실행 |

### 5.2 테스트 데이터

| 항목 | 값 |
|------|-----|
| 테스트 유저 | 10,000명 |
| 초기 잔액 | 1,000,000원 |
| 콘서트 | 3개 |
| 스케줄 | 9개 (콘서트당 3일) |
| 좌석 | 스케줄당 50석 |

### 5.3 도구

| 도구 | 용도 | 비용 |
|------|------|------|
| JMeter 5.6.3 | 부하 테스트 | 무료 (오픈소스) |
| wrk | 보조 검증 | 무료 (오픈소스) |
| docker stats | 리소스 모니터링 | 무료 |

---

## 6. 리스크 및 대응

| 리스크 | 영향 | 대응 방안 |
|--------|------|----------|
| DB 커넥션 풀 고갈 | 요청 실패 급증 | 커넥션 풀 모니터링, 적정값 튜닝 |
| Redis 장애 | 대기열/락 불가 | Redis FLUSHALL로 초기화 |
| 메모리 부족 (OOM) | 컨테이너 재시작 | 최소 512MB 이상 할당 |
| JMeter 스레드 한계 | 테스트 불가 | 로컬 머신 한계 (~4,000 스레드) |
| Mac 프록시 설정 | 요청 실패 | `networksetup -setwebproxystate "Wi-Fi" off` |

---

## 7. 결론

### 부하 테스트가 필요한 이유

1. **티켓 오픈은 단 한 번의 기회** - 실패하면 복구 불가
2. **중복 예약은 절대 발생하면 안 됨** - 현장 혼란, 보상 비용
3. **적정 스펙을 모르면 과투자 또는 장애 발생**

### 기대 효과

- 시스템 한계점 파악 → 장애 예방
- 적정 서버 스펙 도출 → 인프라 비용 최적화
- 동시성 제어 검증 → 중복 예약 0건 보장
- 데이터 기반 의사결정 → 스케일 아웃 시점 판단